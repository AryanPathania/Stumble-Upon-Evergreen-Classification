{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stumble Upon Evergreen Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2Uoey1tsqsg"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKbURi8Wt8p7",
        "outputId": "95e50547-0303-4bc0-f857-4319b1d4c566"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SthLeTv0t9lM"
      },
      "source": [
        "df_train = pd.read_table(\"/content/train.tsv\")\r\n",
        "df_test = pd.read_table(\"/content/test.tsv\")\r\n",
        "sample_sub = pd.read_csv(\"/content/sampleSubmission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yf5aL6HuQYF"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "def boilerplate_pre(data):\r\n",
        "    '''\r\n",
        "    This will only take body of the article; if there is no body than we'll take the title \r\n",
        "    '''\r\n",
        "    jsonData = json.loads(data)\r\n",
        "\r\n",
        "    try:\r\n",
        "        x = jsonData[\"body\"]\r\n",
        "        x = ' '.join(x.split(' ')[-400:])\r\n",
        "    except:\r\n",
        "        x = jsonData[\"title\"]\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF5-3Ws7uTcj"
      },
      "source": [
        "# applies above func and stores result in a new column\r\n",
        "df_train['main'] = df_train.boilerplate.map(boilerplate_pre)\r\n",
        "df_train = df_train.dropna()\r\n",
        "df_test['main'] = df_test.boilerplate.map(boilerplate_pre)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHmGTVtTveAc"
      },
      "source": [
        "df_train.drop(\"boilerplate\",axis = 1, inplace=True)\r\n",
        "df_test.drop(\"boilerplate\", axis = 1, inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "Bacp0_Quub19",
        "outputId": "e91c8e8b-0afc-4adc-b3e6-a503d6fefdaa"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>urlid</th>\n",
              "      <th>alchemy_category</th>\n",
              "      <th>alchemy_category_score</th>\n",
              "      <th>avglinksize</th>\n",
              "      <th>commonlinkratio_1</th>\n",
              "      <th>commonlinkratio_2</th>\n",
              "      <th>commonlinkratio_3</th>\n",
              "      <th>commonlinkratio_4</th>\n",
              "      <th>compression_ratio</th>\n",
              "      <th>embed_ratio</th>\n",
              "      <th>framebased</th>\n",
              "      <th>frameTagRatio</th>\n",
              "      <th>hasDomainLink</th>\n",
              "      <th>html_ratio</th>\n",
              "      <th>image_ratio</th>\n",
              "      <th>is_news</th>\n",
              "      <th>lengthyLinkDomain</th>\n",
              "      <th>linkwordscore</th>\n",
              "      <th>news_front_page</th>\n",
              "      <th>non_markup_alphanum_characters</th>\n",
              "      <th>numberOfLinks</th>\n",
              "      <th>numwords_in_url</th>\n",
              "      <th>parametrizedLinkRatio</th>\n",
              "      <th>spelling_errors_ratio</th>\n",
              "      <th>label</th>\n",
              "      <th>main</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
              "      <td>4042</td>\n",
              "      <td>business</td>\n",
              "      <td>0.789131</td>\n",
              "      <td>2.055556</td>\n",
              "      <td>0.676471</td>\n",
              "      <td>0.205882</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.023529</td>\n",
              "      <td>0.443783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.090774</td>\n",
              "      <td>0</td>\n",
              "      <td>0.245831</td>\n",
              "      <td>0.003883</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>5424</td>\n",
              "      <td>170</td>\n",
              "      <td>8</td>\n",
              "      <td>0.152941</td>\n",
              "      <td>0.079130</td>\n",
              "      <td>0</td>\n",
              "      <td>themselves Traffic Predictors IBM also sees da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://www.popsci.com/technology/article/2012-...</td>\n",
              "      <td>8471</td>\n",
              "      <td>recreation</td>\n",
              "      <td>0.574147</td>\n",
              "      <td>3.677966</td>\n",
              "      <td>0.508021</td>\n",
              "      <td>0.288770</td>\n",
              "      <td>0.213904</td>\n",
              "      <td>0.144385</td>\n",
              "      <td>0.468649</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.098707</td>\n",
              "      <td>0</td>\n",
              "      <td>0.203490</td>\n",
              "      <td>0.088652</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>4973</td>\n",
              "      <td>187</td>\n",
              "      <td>9</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.125448</td>\n",
              "      <td>1</td>\n",
              "      <td>games it s clearly electronic but still more t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://www.menshealth.com/health/flu-fighting-...</td>\n",
              "      <td>1164</td>\n",
              "      <td>health</td>\n",
              "      <td>0.996526</td>\n",
              "      <td>2.382883</td>\n",
              "      <td>0.562016</td>\n",
              "      <td>0.321705</td>\n",
              "      <td>0.120155</td>\n",
              "      <td>0.042636</td>\n",
              "      <td>0.525448</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.072448</td>\n",
              "      <td>0</td>\n",
              "      <td>0.226402</td>\n",
              "      <td>0.120536</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>2240</td>\n",
              "      <td>258</td>\n",
              "      <td>11</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.057613</td>\n",
              "      <td>1</td>\n",
              "      <td>Apples The most popular source of antioxidants...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://www.dumblittleman.com/2007/12/10-foolpr...</td>\n",
              "      <td>6684</td>\n",
              "      <td>health</td>\n",
              "      <td>0.801248</td>\n",
              "      <td>1.543103</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.480725</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.095861</td>\n",
              "      <td>0</td>\n",
              "      <td>0.265656</td>\n",
              "      <td>0.035343</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>2737</td>\n",
              "      <td>120</td>\n",
              "      <td>5</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.100858</td>\n",
              "      <td>1</td>\n",
              "      <td>to follow regularly Don t worry about not gett...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://bleacherreport.com/articles/1205138-the...</td>\n",
              "      <td>9006</td>\n",
              "      <td>sports</td>\n",
              "      <td>0.719157</td>\n",
              "      <td>2.676471</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.123457</td>\n",
              "      <td>0.043210</td>\n",
              "      <td>0.446143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.024908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.228887</td>\n",
              "      <td>0.050473</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>12032</td>\n",
              "      <td>162</td>\n",
              "      <td>10</td>\n",
              "      <td>0.098765</td>\n",
              "      <td>0.082569</td>\n",
              "      <td>0</td>\n",
              "      <td>simultaneously poking at greatness and insanit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  ...                                               main\n",
              "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...  ...  themselves Traffic Predictors IBM also sees da...\n",
              "1  http://www.popsci.com/technology/article/2012-...  ...  games it s clearly electronic but still more t...\n",
              "2  http://www.menshealth.com/health/flu-fighting-...  ...  Apples The most popular source of antioxidants...\n",
              "3  http://www.dumblittleman.com/2007/12/10-foolpr...  ...  to follow regularly Don t worry about not gett...\n",
              "4  http://bleacherreport.com/articles/1205138-the...  ...  simultaneously poking at greatness and insanit...\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "scp0VYlRuuAI",
        "outputId": "8adca049-2bf4-4a38-90d6-c4a0f86be5a0"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>urlid</th>\n",
              "      <th>alchemy_category</th>\n",
              "      <th>alchemy_category_score</th>\n",
              "      <th>avglinksize</th>\n",
              "      <th>commonlinkratio_1</th>\n",
              "      <th>commonlinkratio_2</th>\n",
              "      <th>commonlinkratio_3</th>\n",
              "      <th>commonlinkratio_4</th>\n",
              "      <th>compression_ratio</th>\n",
              "      <th>embed_ratio</th>\n",
              "      <th>framebased</th>\n",
              "      <th>frameTagRatio</th>\n",
              "      <th>hasDomainLink</th>\n",
              "      <th>html_ratio</th>\n",
              "      <th>image_ratio</th>\n",
              "      <th>is_news</th>\n",
              "      <th>lengthyLinkDomain</th>\n",
              "      <th>linkwordscore</th>\n",
              "      <th>news_front_page</th>\n",
              "      <th>non_markup_alphanum_characters</th>\n",
              "      <th>numberOfLinks</th>\n",
              "      <th>numwords_in_url</th>\n",
              "      <th>parametrizedLinkRatio</th>\n",
              "      <th>spelling_errors_ratio</th>\n",
              "      <th>main</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.lynnskitchenadventures.com/2009/04/...</td>\n",
              "      <td>5865</td>\n",
              "      <td>recreation</td>\n",
              "      <td>0.443906</td>\n",
              "      <td>2.558140</td>\n",
              "      <td>0.389706</td>\n",
              "      <td>0.257353</td>\n",
              "      <td>0.044118</td>\n",
              "      <td>0.022059</td>\n",
              "      <td>0.489572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.067143</td>\n",
              "      <td>0</td>\n",
              "      <td>0.230285</td>\n",
              "      <td>0.199438</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>5643</td>\n",
              "      <td>136</td>\n",
              "      <td>3</td>\n",
              "      <td>0.242647</td>\n",
              "      <td>0.080597</td>\n",
              "      <td>I usually buy my enchilada sauce Yes I knew I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://lolpics.se/18552-stun-grenade-ar</td>\n",
              "      <td>782</td>\n",
              "      <td>culture_politics</td>\n",
              "      <td>0.135844</td>\n",
              "      <td>3.771429</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.051282</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.042857</td>\n",
              "      <td>0</td>\n",
              "      <td>0.365962</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>382</td>\n",
              "      <td>39</td>\n",
              "      <td>2</td>\n",
              "      <td>0.128205</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>funny pictures at lolpics.se. the best funny ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://www.xcelerationfitness.com/treadmills.html</td>\n",
              "      <td>6962</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>2.269565</td>\n",
              "      <td>0.495726</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.170940</td>\n",
              "      <td>0.170940</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0</td>\n",
              "      <td>0.161901</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>2420</td>\n",
              "      <td>117</td>\n",
              "      <td>1</td>\n",
              "      <td>0.581197</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>treadmills, stair, climbers, treadmills</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://www.bloomberg.com/news/2012-02-06/syria...</td>\n",
              "      <td>7640</td>\n",
              "      <td>culture_politics</td>\n",
              "      <td>0.90259</td>\n",
              "      <td>2.523490</td>\n",
              "      <td>0.705502</td>\n",
              "      <td>0.346278</td>\n",
              "      <td>0.122977</td>\n",
              "      <td>0.090615</td>\n",
              "      <td>0.449366</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058081</td>\n",
              "      <td>0</td>\n",
              "      <td>0.146593</td>\n",
              "      <td>0.005964</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>5559</td>\n",
              "      <td>309</td>\n",
              "      <td>10</td>\n",
              "      <td>0.038835</td>\n",
              "      <td>0.063126</td>\n",
              "      <td>twice the average of 34 in 2011 according to t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://www.wired.com/gadgetlab/2011/12/stem-tu...</td>\n",
              "      <td>3589</td>\n",
              "      <td>science_technology</td>\n",
              "      <td>0.486363</td>\n",
              "      <td>1.848000</td>\n",
              "      <td>0.470968</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.453757</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.093023</td>\n",
              "      <td>0</td>\n",
              "      <td>0.244141</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>2209</td>\n",
              "      <td>155</td>\n",
              "      <td>10</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>0.065341</td>\n",
              "      <td>Quirky s Stem turns any citrus fruit into an a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  ...                                               main\n",
              "0  http://www.lynnskitchenadventures.com/2009/04/...  ...  I usually buy my enchilada sauce Yes I knew I ...\n",
              "1            http://lolpics.se/18552-stun-grenade-ar  ...   funny pictures at lolpics.se. the best funny ...\n",
              "2  http://www.xcelerationfitness.com/treadmills.html  ...            treadmills, stair, climbers, treadmills\n",
              "3  http://www.bloomberg.com/news/2012-02-06/syria...  ...  twice the average of 34 in 2011 according to t...\n",
              "4  http://www.wired.com/gadgetlab/2011/12/stem-tu...  ...  Quirky s Stem turns any citrus fruit into an a...\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "AjRQkzlRu8Dt",
        "outputId": "93f1eb01-9b42-4aa7-d511-dc69d38e714b"
      },
      "source": [
        "# get length of all the messages in the train set\r\n",
        "seq_len = [len(i.split()) for i in df_train.main]\r\n",
        "\r\n",
        "pd.Series(seq_len).hist(bins = 30)\r\n",
        "print(max(seq_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06UkFydTvKYg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "x_train, x_val, y_train, y_val = train_test_split(df_train.main.values, df_train.label.values, test_size=0.1, random_state=42, stratify=df_train.label.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g0bShu2wPVi",
        "outputId": "f5335d16-59e3-4fe2-eb0c-0125e4a2843b"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq8x-vK5w6eD"
      },
      "source": [
        "from transformers import AdamW\r\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "from transformers import BertTokenizer, BertConfig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqeX6bRrxQhm"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",  do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwqECSAzyDmc"
      },
      "source": [
        "train_token = tokenizer.batch_encode_plus(\r\n",
        "    list(x_train),\r\n",
        "    add_special_tokens=True,\r\n",
        "    return_attention_mask = True,\r\n",
        "    padding = \"max_length\",\r\n",
        "    max_length = 405,\r\n",
        "    return_tensors = \"pt\",\r\n",
        "    truncation = True\r\n",
        ")\r\n",
        "\r\n",
        "valid_token = tokenizer.batch_encode_plus(\r\n",
        "    list(x_val),\r\n",
        "    add_special_tokens=True,\r\n",
        "    return_attention_mask = True,\r\n",
        "    padding = \"max_length\",\r\n",
        "    max_length = 405,\r\n",
        "    return_tensors = \"pt\",\r\n",
        "    truncation = True\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRxMOzRKHRUz",
        "outputId": "63d0cd21-ddf1-4cd6-fed3-08429ef2f5c3"
      },
      "source": [
        "# sample data\r\n",
        "text = [\"Bert tokenizer example\",\"let's see how it works\"]\r\n",
        "\r\n",
        "# encode text\r\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True)\r\n",
        "\r\n",
        "# output\r\n",
        "print(sent_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 14324, 19204, 17629, 2742, 102, 0, 0, 0], [101, 2292, 1005, 1055, 2156, 2129, 2009, 2573, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEVc5d3rzDBg",
        "outputId": "cb852e4a-1f09-41a3-f72e-e5a326045c60"
      },
      "source": [
        "len(train_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy4yPEO2HLPC"
      },
      "source": [
        "batch = 8\r\n",
        "\r\n",
        "input_ids_train = train_token['input_ids']\r\n",
        "attention_masks_train = train_token['attention_mask']\r\n",
        "labels_train = torch.tensor(list(y_train))#.float()\r\n",
        "\r\n",
        "input_ids_val = valid_token['input_ids']\r\n",
        "attention_masks_val = valid_token['attention_mask']\r\n",
        "labels_val = torch.tensor(list(y_val))#.float()\r\n",
        "\r\n",
        "# making dataset\r\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\r\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\r\n",
        "\r\n",
        "# making dataloader\r\n",
        "train_loader = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch)\r\n",
        "valid_loader = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX1WOqJCIeYz"
      },
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc9WKo1rI3wC"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk-p6uFjIZIg",
        "outputId": "fad73834-58b5-4152-fda1-06160762a258"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",output_hidden_states = False,\r\n",
        "                                                      output_attentions = False, num_labels=2)\r\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAgT-C0yHWVz"
      },
      "source": [
        "FULL_FINETUNING = True\r\n",
        "if FULL_FINETUNING:\r\n",
        "    param_optimizer = list(model.named_parameters())\r\n",
        "    no_decay = ['bias', 'gamma', 'beta']\r\n",
        "    optimizer_grouped_parameters = [\r\n",
        "        {'params' : [p for n,p in param_optimizer if not any(nd in n for nd in no_decay)],\r\n",
        "         'weight_decay_rate' : 0.01},\r\n",
        "         {'params' : [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\r\n",
        "          'weight_decay_rate':0.0}\r\n",
        "    ]\r\n",
        "else:\r\n",
        "    param_optimizer = list(model.classifier.named_parameters())\r\n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n,p in param_optimizer]}]\r\n",
        "\r\n",
        "optimizer = AdamW(\r\n",
        "    optimizer_grouped_parameters,\r\n",
        "    lr = 3e-5,\r\n",
        "    eps = 1e-8\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NkqBlqcI2GE"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\r\n",
        "\r\n",
        "epochs = 5\r\n",
        "max_grad_norm = 1.0\r\n",
        "\r\n",
        "# Total number of training steps is number of batches * number of epochs\r\n",
        "total_steps = len(train_loader) * epochs\r\n",
        "\r\n",
        "# Create the learning rate scheduler\r\n",
        "scheduler = get_linear_schedule_with_warmup(\r\n",
        "    optimizer,\r\n",
        "    num_warmup_steps = 0,\r\n",
        "    num_training_steps = total_steps\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdB2mQXJJsBl",
        "outputId": "d98ecab4-240a-4f0d-8565-0d3307efbbf2"
      },
      "source": [
        "train_losses = []\r\n",
        "validation_losses = []\r\n",
        "\r\n",
        "for epoch in range(1, epochs+1):\r\n",
        "    train_loss = 0.0\r\n",
        "    valid_loss = 0.0\r\n",
        "    model.train()\r\n",
        "    for data in train_loader:\r\n",
        "        data = tuple(t.to(device) for t in data)\r\n",
        "        inputs, masks, labels = data\r\n",
        "\r\n",
        "        model.zero_grad()\r\n",
        "        outputs = model(inputs,token_type_ids = None, attention_mask = masks, labels=labels)\r\n",
        "        loss = outputs[0]\r\n",
        "        loss.backward()\r\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\r\n",
        "        optimizer.step()\r\n",
        "        # scheduler.step()\r\n",
        "        train_loss += loss.item()\r\n",
        "        logits = outputs[1].detach().cpu().numpy()\r\n",
        "        scheduler.step()\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    for data in valid_loader:\r\n",
        "        data = tuple(t.to(device) for t in data)\r\n",
        "        inputs, masks, labels = data\r\n",
        "        model.zero_grad()\r\n",
        "        outputs = model(inputs, attention_mask = masks,token_type_ids = None, labels=labels)\r\n",
        "        loss = outputs[0]\r\n",
        "\r\n",
        "        valid_loss += loss.item()\r\n",
        "        logits = outputs[1].detach().cpu().numpy()\r\n",
        "    \r\n",
        "    \r\n",
        "     # calculate average losses\r\n",
        "    train_loss = train_loss/len(train_loader)\r\n",
        "    valid_loss = valid_loss/len(valid_loader)\r\n",
        "    train_losses.append(train_loss)\r\n",
        "    validation_losses.append(valid_loss)\r\n",
        "\r\n",
        "    print(f\"Epoch {epoch}: \\t Training Loss:  {train_loss} \\t Validation Loss:  {valid_loss}\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: \t Training Loss:  0.4955746812853389 \t Validation Loss:  0.46048739288122426\n",
            "Epoch 2: \t Training Loss:  0.4345232671274481 \t Validation Loss:  0.4430293976779907\n",
            "Epoch 3: \t Training Loss:  0.37184449438063893 \t Validation Loss:  0.5804665714342107\n",
            "Epoch 4: \t Training Loss:  0.2945124752788196 \t Validation Loss:  0.7563374011567042\n",
            "Epoch 5: \t Training Loss:  0.23217021398550758 \t Validation Loss:  0.8412996865408395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3UTNeP-hmI_"
      },
      "source": [
        "test_text = df_test[\"main\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkC0qyRRKUGA"
      },
      "source": [
        "token_test = tokenizer.batch_encode_plus(\r\n",
        "        list(test_text), \r\n",
        "        add_special_tokens=True, \r\n",
        "        return_attention_mask=True, \r\n",
        "        #pad_to_max_length=True,\r\n",
        "        padding='max_length', \r\n",
        "        max_length=405, \r\n",
        "        return_tensors='pt',\r\n",
        "        truncation=True\r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCvGJzcGhtQl"
      },
      "source": [
        "test_input_ids = token_test['input_ids']\r\n",
        "test_attention_masks = token_test['attention_mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZs5izjxmXVM"
      },
      "source": [
        "sample_sub.drop(\"label\", axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwylIoz9mg4L"
      },
      "source": [
        "predict__ = []\r\n",
        "with torch.no_grad():\r\n",
        "  for input, mask in zip(test_input_ids, test_attention_masks):\r\n",
        "    preds = model(input.unsqueeze(0).to(device), mask.unsqueeze(0).to(device))\r\n",
        "    preds = preds[0]\r\n",
        "    preds = preds.detach().cpu().numpy()\r\n",
        "    \r\n",
        "    preds = np.argmax(preds, axis=1)\r\n",
        "    # print(preds)\r\n",
        "    predict__.append(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEAARYK9bj0k"
      },
      "source": [
        "outputs = []\r\n",
        "for count,i in enumerate(predict__):\r\n",
        "    for j in i:\r\n",
        "        outputs.append(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vA7WVF_cxnU"
      },
      "source": [
        "sample_sub[\"label\"] = outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "fvg1AZO6c-d6",
        "outputId": "ae3e047e-ea65-43ba-99ce-1c3ec742a545"
      },
      "source": [
        "sample_sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>urlid</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>782</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6962</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7640</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3589</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   urlid  label\n",
              "0   5865      1\n",
              "1    782      0\n",
              "2   6962      1\n",
              "3   7640      0\n",
              "4   3589      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCJRyJ7ndAHI"
      },
      "source": [
        "sample_sub.to_csv(\"/content/submission4.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLqGsvwidFt2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}